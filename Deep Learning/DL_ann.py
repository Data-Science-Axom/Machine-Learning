# -*- coding: utf-8 -*-
"""ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1etSxR1iR6M2WxkL081-mDJNf_rPCI8ZX

**Artificial Neural Networks**

Part 1 - Data Preprocessing
"""

#importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

from google.colab import files
uploaded = files.upload()

#importing the dataset
dataset=pd.read_csv('Churn_Modelling.csv')
x = dataset.iloc[:,3:13].values
y = dataset.iloc[:,-1].values

#dataset

#x.shape

#y

# Encoding categorical data
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
x1=ColumnTransformer(
    transformers=[
        ("OneHot",        # Just a name
         OneHotEncoder(), # The transformer class
         [1]              # The column(s) to be applied on.
         )
    ],
    remainder='passthrough' # donot apply anything to the remaining columns
)
x = x1.fit_transform(x.tolist())
#labelencoder_x = LabelEncoder()
#x[:, 1] = labelencoder_x.fit_transform(x[:, 1])
#onehotencoder = OneHotEncoder(categorical_features=[1])
#x = onehotencoder.fit_transform(x).toarray()

from sklearn.preprocessing import LabelEncoder
labelencoder_x_2 = LabelEncoder()
x[:, 4] = labelencoder_x_2.fit_transform(x[:, 4])
x=x[:,1:]                                           #to avoid falling into the dummy variable trap

#x[0:7]

#splitting the dataset into training set and test set
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y ,test_size = 0.2, random_state = 0)

#feature scaling
from sklearn.preprocessing import StandardScaler
sc_x= StandardScaler()
x_train = sc_x.fit_transform(x_train)
x_test = sc_x.transform(x_test)

#x_train.shape

"""Part 2 - *ANN*"""

# Commented out IPython magic to ensure Python compatibility.
"""NOTE: Current TensorFlow version is 2.2.0-rc1. To use TF 1.x instead,
restart your runtime (Ctrl+M .) and run "%tensorflow_version 1.x" before
you run "import tensorflow"""
# %tensorflow_version 1.8.0

#importing the keras libraries and packages
import keras
from keras.models import Sequential
from keras.layers import Dense

#If wanna use theano instead of keras, https://stackoverflow.com/questions/42177658/how-to-switch-backend-with-keras-from-tensorflow-to-theano

#initialising the ANN
classifier = Sequential()

#adding the input lapyer and the 1st hidden layer
classifier.add(Dense(units=6,kernel_initializer="uniform",activation="relu",input_dim=11))
#classifier.add(Dense(output_dim=6,init='uniform',activation='relu',,input_dim=11))

#adding the 2nd hidden layer
classifier.add(Dense(units=6,kernel_initializer="uniform",activation="relu"))
#classifier.add(Dense(output_dim=6,init='uniform',activation='relu'))

#adding the output layer
classifier.add(Dense(units=1,kernel_initializer="uniform",activation='sigmoid'))     
#act='soft_max' fn if more than two categories & o/p = no. of categories of DV

#compiling the ANN
classifier.compile(optimizer="adam",loss="binary_crossentropy",metrics=["accuracy"])

#fitting the ANN to the Training set
classifier.fit(x_train, y_train, batch_size=10, epochs=100)
#classifier.fit(x_train, y_train, batch_size=10, nb_epochs=100)

"""Part 3 - Making the Predictions and evaluating the Model"""

#predicting the test set results
y_pred=classifier.predict(x_test)
y_pred = (y_pred > 0.5)

#y_pred

#making the confusion matrix
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test, y_pred)

#cm

#(1500 + 175)/2000                  #accuracy